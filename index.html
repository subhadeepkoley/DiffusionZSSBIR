<!DOCTYPE html>
<html>

<head>
    <style>
        td,
        th {
            border: 0px solid black;
        }

        img {
            padding: 5px;
        }
    </style>
    <title>Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">
    <link rel="stylesheet" href="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <script src="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title" , style="color:purple;">Text-to-Image Diffusion Models are
                        Great Sketch-Photo Matchmakers</h1>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">
                            <a href="https://subhadeepkoley.github.io/">Subhadeep Koley</a><sup>1,2</sup>,</span>
                        <span class="author-block">
                            <a href="https://ayankumarbhunia.github.io/">Ayan Kumar Bhunia</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a href="https://aneeshan95.github.io/">Aneeshan Sain</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a href="http://www.pinakinathc.me/">Pinaki Nath Chowdhury</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a href="https://www.surrey.ac.uk/people/tao-xiang">Tao
                                Xiang</a><sup>1,2</sup>,</span>
                        <span class="author-block">
                            <a href="https://www.surrey.ac.uk/people/yi-zhe-song">Yi-Zhe
                                Song</a><sup>1,2</sup></span>
                        </span>
                    </div>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>SketchX, CVSSP, University of Surrey, United
                            Kingdom</span>
                        <span class="author-block"><sup>2</sup>iFlyTek-Surrey Joint Research Centre on Artifiial
                            Intelligence</span>
                    </div>
                    <!--     <div class="column has-text-centered">
                     <a href="as">ICLR 2023</a>
                     </span>
                     </div> -->
                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- PDF Link. -->
                            <span class="link-block">
                                <a href="https://arxiv.org/pdf/2403.07214"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>Paper (PDF)</span>
                                </a>
                            </span>
                            <span class="link-block">
                                <a href="https://arxiv.org/abs/2403.07214"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="ai ai-arxiv"></i>
                                    </span>
                                    <span>arXiv</span>
                                </a>
                            </span>
                            <!-- Video Link. -->
                            <span class="link-block">
                                <a href="" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fab fa-youtube"></i>
                                    </span>
                                    <span>Video (YouTube)</span>
                                </a>
                            </span>

                            <!-- Dataset Link. -->
                            <span class="link-block">
                                <a href="" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="far fa-images"></i>
                                    </span>
                                    <span>Poster</span>
                                </a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <img class="round" style="width:1500px" src="./static/images/teaser.png" />
            <h2 class="subtitle has-text-centered">
                <span class="dnerf"></span> (Left): Sketch-based image retrieval frameworks usually employ ImageNet
                pre-trained CNNs, JFT-trained
                vision transformers (ViT), or visual encoders of vision-language models like CLIP as backbone feature
                extractors. Rich
                knowledge from large-scale pre-training offers a good initialisation, which when further fine-tuned on
                sketch-photo datasets, performs
                way better than training from random initialisation. While one can extract features either by discarding
                the classification head for
                ImageNet pre-trained models, auxiliary task head for self-supervised models, or by using CLIP's visual
                encoder, text-to-image diffusion
                models (e.g., stable diffusion) lack any specific feature embedding space. However, we find that its
                intermediate representations implicitly
                hold robust cross-modal features at multiple granularities. Unlike prior SBIR backbones, pre-trained
                with discriminative tasks, we propose
                to leverage denoising diffusion models pre-trained with text-to-image generative tasks to bridge the
                sketch-photo domain gap. Being a
                text-to-image generation model trained on a large corpus of text-image pairs (LAION), it holds both
                semantic and shape prior.
                PCA representation (right) of intermediate UNet features (sketch/photo) from different upsampling blocks
                depict
                that they share significant semantic similarity (denoted by similar colours).

            </h2>
        </div>
    </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    This paper, for the first time, explores text-to-image diffusion models for Zero-Shot Sketch-based
                    Image Retrieval (ZS-SBIR). We highlight a pivotal discovery: the capacity of text-to-image diffusion
                    models to seamlessly bridge the gap between sketches and photos. This proficiency is underpinned by
                    their robust cross-modal capabilities and shape bias, findings that are substantiated through our
                    pilot studies. In order to harness pre-trained diffusion models effectively, we introduce a
                    straightforward yet powerful strategy focused on two key aspects: selecting optimal feature layers
                    and utilising visual and textual prompts. For the former, we identify which layers are most enriched
                    with information and are best suited for the specific retrieval requirements (category-level or
                    fine-grained). Then we employ visual and textual prompts to guide the model's feature extraction
                    process, enabling it to generate more discriminative and contextually relevant cross-modal
                    representations. Extensive experiments on several benchmark datasets validate significant
                    performance improvements.
                    </p>
                </div>
            </div>
        </div>

        <!-- <section class="hero teaser">
         <div class="container is-max-desktop">
            <div class="hero-body">
               <iframe width="720" height="480" src="https://www.youtube.com/embed/k7xFbELpnv4?">
               </iframe>
               <h2 class="subtitle has-text-centered">
                  <span class="dnerf"></span>
               </h2>
            </div>
         </div>
      </section> -->

        <!--/ Abstract. -->
        <!-- Paper video. -->
        <section class="section">
            <div class="container is-max-desktop">
                <!-- Abstract. -->
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Diffusion Feature Extraction</h2>
                        <div class="content has-text-justified">
                            </h2>
                            <center>
                                <img src="./static/images/diffusion_feature.png" alt="" border=0 height=300
                                    width=650></img></ </center>
                                <h5 class="subtitle has-text-centered">
                                    Feature extraction via text-to-image diffusion model.
                                </h5>
                                &nbsp;
                        </div>
                    </div>
                </div>
        </section>
        <section class="section">
            <div class="container is-max-desktop">
                <!-- Abstract. -->
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Architecture</h2>
                        <div class="content has-text-justified">
                            </h2>
                            <center>
                                <img src="./static/images/arch.png" alt="" border=0 height=300 width=650></img></
                                    </center>
                                <h5 class="subtitle has-text-centered">
                                    Given the frozen Stabel Diffusion backbone feature extractor, our
                                    method learns a single textual prompt, and sketch/photo-specific
                                    visual prompts via triplet loss.
                                </h5 &nbsp; </div>
                        </div>
                    </div>
        </section>
        <section class="hero">
            <div class="hero-body">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">Results</h2>
                            <div class="content has-text-justified">
                                <center>
                                    <img src="static/images/pca.png" border=0 height=200 width=1500 />
                                </center>
                                <h5 class="subtitle has-text-centered">
                                    PCA representation of Stabvel Diffusion internal features from upsampling layers of
                                    UNet for different time-steps. Different regions of sketch and photo feature maps
                                    from [200, 300] (highlighted in red) portray strong semantic
                                    feature correspondence (represented by the same colours in the PCA map), while the
                                    features from the later time-steps are non-aligned.
                                    <br>
                                    <br>
                                    <center>
                                        <img src="static/images/plot.png" border=0 height=150 width=800 />
                                    </center>
                                    <h5 class="subtitle has-text-centered">
                                        Plots showing low-data scenario performance for ZS-SBIR (left) and ZS-FG-SBIR
                                        (right) setup on Sketchy dataset.
                                        <br>
                                        <br>
                                        <center>
                                            <img src="static/images/plot_1.png" border=0 height=400 width=900 />
                                        </center>
                                        <h5 class="subtitle has-text-centered">
                                            Quantitative results on Sketchy for ZS-SBIR (mAP@200) and ZS-FG-SBIR
                                            (Acc.@1) setup for different denoising time-steps (left) and visual prompt
                                            border width (right).
                                            <br>
                                            <br>

                            </div>
                        </div>
                    </div>
                </div>
                <section class="section" id="BibTeX">
                    <div class="container is-max-desktop content">
                        <h2 class="title">BibTeX</h2>
                        <pre><code>@inproceedings{koley2024text,
title={{Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers}},
author={Koley, Subhadeep and Bhunia, Ayan Kumar and Sain, Aneeshan and Chowdhury, Pinaki Nath and Xiang, Tao and Song, Yi-Zhe},
booktitle={CVPR},
year={2024}
}</code></pre>
                    </div>
                </section>
                <script>
                    const viewers = document.querySelectorAll(".image-compare");
                    viewers.forEach((element) => {
                        let view = new ImageCompare(element, {
                            hoverStart: true,
                            addCircle: true
                        }).mount();
                    });

                    $(document).ready(function () {
                        var editor = CodeMirror.fromTextArea(document.getElementById("bibtex"), {
                            lineNumbers: false,
                            lineWrapping: true,
                            readOnly: true
                        });
                        $(function () {
                            $('[data-toggle="tooltip"]').tooltip()
                        })
                    });
                </script>
                <br>

                <p style="text-align:center"> <img src="https://badges.toozhao.com/badges/01HTSPGSB3RXPCDHAY58XWJAA5/green.svg" /> </a></p>

                <p style="text-align:center"> Copyright: <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                        CC
                        BY-NC-SA 4.0</a> © Subhadeep Koley | Last updated: 05 April 2024 | Good artists <a
                        href="https://nerfies.github.io/"> copy</a>, great artists steal.</a></p>
                </body>

</html>